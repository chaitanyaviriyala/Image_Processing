{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - Background Substraction\n",
    "ATRIM - Option Datasim\n",
    "\n",
    "Ecole Centrale Nantes\n",
    "\n",
    "Diana Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants: (FILL IN YOUR NAMES AND LASTNAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKGROUND SUBSTRACTION \n",
    "\n",
    "The goal of this TP is to enhance the video of a neurointervention  to improve the visualization of moving tools. To this end you will implement a pipeline of image processing methods to detect the moving tools automatically. \n",
    "\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "As the brain is mostly static one way to detect the moving tools is to substract the background (first image) from each of the subsequent images. However, the results of this step need to be further improved. To this end, you will design a pipilene with the methods learnt in this course to produce a binary mask for the pixels that belong to the tools. \n",
    "\n",
    "In your pipeline use at least:\n",
    "- one histogram transformation\n",
    "- one morphological operation\n",
    "- one filtering operation in the spatial domain\n",
    "- one filtering operation in the spectral domain\n",
    "- one segmentation method\n",
    "\n",
    "_The same pipeline should be applied to every image_\n",
    "\n",
    "\n",
    "#### Expected output\n",
    "\n",
    "The output of your image processing pipeline should be one binary image mask (with values 0 or 1) for every input image of the sequence, where \n",
    "- the zero valued pixels indicate the moving tools inside each image.  \n",
    "- the pixels with value 1 indicate the background (not a moving tool)\n",
    "\n",
    "To validate the proposed method, a human has annotated (manually drawn) the tools of interest within the images. The annotated pixels belong either to catheters or guidewires. **Your masks should be as close as possible to the human annotations.**\n",
    "\n",
    "\n",
    "#### Visualization of data and manual annotations\n",
    "\n",
    "- Data visualization  (**do not include in final version**): visualize the neurointervention images in the ``` catheter``` folder with name ```frame_#```\n",
    "\n",
    "- Individual Annotation visualization  (** do not include in final version**): visualize the manual annotations in the ```catheter``` folder with names ``` #_MicroCath``` and ```#_GuideWire```. \n",
    "\n",
    "- Individual Annotation visualization  (** do not include in final version**): visualize the full manual annotation (union of the guidewire and microcatheter masks) by composing the union of the ``` #_MicroCath``` and ```#_GuideWire```. It should also be a binary mask.\n",
    "\n",
    "\n",
    "\n",
    "#### Experimental (quantitative and qualitative  validation)\n",
    "\n",
    "To compare your results and the manual annotations use the mean SAD (Sum of Absolute Differences) and the SNR (Signal to Noise Ratio) errors between your  mask and  the **full** manual mask. \n",
    "\n",
    "Present the results qualitatively and quantitatively:\n",
    "\n",
    "- Qualitatively: \n",
    "     - Show your mask side by side with the manually annotated mask\n",
    "     - Create an enhanced image suitable for guidance: enhance the contrast of the image and overlay your mask on the green channel of the enhanced image.\n",
    "\n",
    "- Quantitatively: \n",
    "    - compute and print the SAD (sum of absolute differences) error per image. \n",
    "    - compute and print the MSE (sum of squared  differences ) error per image.\n",
    "    - compute and print the PSNR (Peak signal to noise ratio) taking as reference image the manual annotations. \n",
    "    - Then compute and print the mean and standard deviation of the three measures (SAD, MSE and PSNR) over the entire sequence.\n",
    "    \n",
    "Hints:\n",
    "```\n",
    "mse = numpy.mean( (img1 - img2) ** 2 )\n",
    "PIXEL_MAX = 255.0 #or 1.0 or max over the signal of interest\n",
    "psnr = 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "```\n",
    "or look at ```skimage.measure``` module\n",
    "\n",
    "You may use modules such as ```scipy```, ```skimage``` or ``sklearn``(e.g. for clustering with K-means or a Gaussian Mixture Model). Ask me for other external modules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORT INSTRUCTIONS\n",
    "\n",
    "#### 1. Intermediate Steps (Code and Description)\n",
    "Report the results of the intermediate steps (when you add or remove a method from the pipeline):\n",
    "- provide a text introduction with the idea that you intend to try\n",
    "- show the implementation of the idea with code \n",
    "- evaluate the quantitative and qualitative changes  when including, varying, adapting, etc the proposed method\n",
    "- Discuss the scores or visualization improvements/degradations \n",
    "\n",
    "#### 2. Final Pipeline (Code and Description)\n",
    "Provide a detailed description of the best performing pipeline. Comment the code such that it is straightforward to relate the pipeline description to the code. Add your conclusions\n",
    "\n",
    "- Describe the final retained pipeline\n",
    "- Give a justification for every step (e.g. supported by experimental intermediate steps or theory). \n",
    "- Add the **commented** code\n",
    "- Display the qualitative and quantitative results \n",
    "- Give your conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
